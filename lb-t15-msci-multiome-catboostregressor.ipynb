{"cells":[{"cell_type":"markdown","metadata":{},"source":["# **ðŸ¥ˆThis Notebook now rank 15 in LB!**\n","+ I used `TruncatedSVD(n_components=128, random_state=42)` both on train and test data.\n","+ CatBoostRegressor is used. To save timeï¼Œ only trained on fold_0. Maybe more fold will help to impore score.\n","+ This notebook is based on [FABIEN CROM](https://www.kaggle.com/code/fabiencrom/msci-multiome-quickstart-w-sparse-matrices). Please Upvoted if help !\n","+ Version_1 is a quick submission and version_2_3 show the training process."]},{"cell_type":"code","execution_count":1,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2022-09-10T04:02:52.747613Z","iopub.status.busy":"2022-09-10T04:02:52.747156Z","iopub.status.idle":"2022-09-10T04:02:54.058805Z","shell.execute_reply":"2022-09-10T04:02:54.057226Z","shell.execute_reply.started":"2022-09-10T04:02:52.747525Z"},"trusted":true},"outputs":[],"source":["import os, gc, pickle\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from colorama import Fore, Back, Style\n","from matplotlib.ticker import MaxNLocator\n","\n","from sklearn.base import BaseEstimator, TransformerMixin\n","from sklearn.model_selection import KFold\n","from sklearn.preprocessing import StandardScaler, scale\n","from sklearn.decomposition import PCA, TruncatedSVD\n","from sklearn.dummy import DummyRegressor\n","from sklearn.pipeline import make_pipeline, Pipeline\n","from sklearn.linear_model import Ridge, LinearRegression, Lasso\n","from sklearn.metrics import mean_squared_error\n","\n","import scipy\n","import scipy.sparse\n","\n","import gc\n","import pickle\n","import warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2022-09-10T04:02:54.061176Z","iopub.status.busy":"2022-09-10T04:02:54.060844Z","iopub.status.idle":"2022-09-10T04:02:54.069040Z","shell.execute_reply":"2022-09-10T04:02:54.067817Z","shell.execute_reply.started":"2022-09-10T04:02:54.061148Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["def correlation_score(y_true, y_pred):\n","    \"\"\"Scores the predictions according to the competition rules. \n","    \n","    It is assumed that the predictions are not constant.\n","    \n","    Returns the average of each sample's Pearson correlation coefficient\"\"\"\n","    if type(y_true) == pd.DataFrame: y_true = y_true.values\n","    if type(y_pred) == pd.DataFrame: y_pred = y_pred.values\n","    if y_true.shape != y_pred.shape: raise ValueError(\"Shapes are different.\")\n","    corrsum = 0\n","    for i in range(len(y_true)):\n","        corrsum += np.corrcoef(y_true[i], y_pred[i])[1, 0]\n","    return corrsum / len(y_true)\n"]},{"cell_type":"markdown","metadata":{},"source":["# Preprocessing and cross-validation\n","\n","We first load all of the training input data for Multiome. It should take less than a minute."]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2022-09-10T04:02:54.072106Z","iopub.status.busy":"2022-09-10T04:02:54.070688Z","iopub.status.idle":"2022-09-10T04:03:55.300044Z","shell.execute_reply":"2022-09-10T04:03:55.298793Z","shell.execute_reply.started":"2022-09-10T04:02:54.072056Z"},"trusted":true},"outputs":[],"source":["%%time\n","train_inputs = scipy.sparse.load_npz(\"../input/multimodal-single-cell-as-sparse-matrix/train_multi_inputs_values.sparse.npz\")"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2022-09-10T04:03:55.303225Z","iopub.status.busy":"2022-09-10T04:03:55.302460Z","iopub.status.idle":"2022-09-10T04:03:59.209511Z","shell.execute_reply":"2022-09-10T04:03:59.208487Z","shell.execute_reply.started":"2022-09-10T04:03:55.303181Z"},"trusted":true},"outputs":[],"source":["train_inputs = train_inputs.astype('float16', copy=False)"]},{"cell_type":"markdown","metadata":{},"source":["## PCA / TruncatedSVD\n","It is not possible to directly apply PCA to a sparse matrix, because PCA has to first \"center\" the data, which destroys the sparsity. This is why we apply `TruncatedSVD` instead (which is pretty much \"PCA without centering\"). It might be better to normalize the data a bit more here, but we will keep it simple."]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2022-09-10T04:04:21.303299Z","iopub.status.busy":"2022-09-10T04:04:21.302921Z","iopub.status.idle":"2022-09-10T04:28:34.330219Z","shell.execute_reply":"2022-09-10T04:28:34.327485Z","shell.execute_reply.started":"2022-09-10T04:04:21.303268Z"},"trusted":true},"outputs":[],"source":["%%time\n","pca = TruncatedSVD(n_components=128, random_state=42)\n","train_inputs = pca.fit_transform(train_inputs)\n","print(pca.explained_variance_ratio_.sum())"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2022-09-10T04:28:34.334960Z","iopub.status.busy":"2022-09-10T04:28:34.333616Z","iopub.status.idle":"2022-09-10T04:28:58.992758Z","shell.execute_reply":"2022-09-10T04:28:58.991451Z","shell.execute_reply.started":"2022-09-10T04:28:34.334916Z"},"trusted":true},"outputs":[],"source":["%%time\n","train_targets = scipy.sparse.load_npz(\"../input/multimodal-single-cell-as-sparse-matrix/train_multi_targets_values.sparse.npz\")"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2022-09-10T04:28:58.995280Z","iopub.status.busy":"2022-09-10T04:28:58.994517Z","iopub.status.idle":"2022-09-10T04:34:46.493950Z","shell.execute_reply":"2022-09-10T04:34:46.492689Z","shell.execute_reply.started":"2022-09-10T04:28:58.995233Z"},"trusted":true},"outputs":[],"source":["%%time\n","pca2 = TruncatedSVD(n_components=128, random_state=42)\n","train_target = pca2.fit_transform(train_targets)\n","print(pca2.explained_variance_ratio_.sum())"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2022-09-10T04:34:46.497125Z","iopub.status.busy":"2022-09-10T04:34:46.496643Z","iopub.status.idle":"2022-09-10T04:34:46.502825Z","shell.execute_reply":"2022-09-10T04:34:46.501583Z","shell.execute_reply.started":"2022-09-10T04:34:46.497091Z"},"trusted":true},"outputs":[],"source":["def save(name, model):\n","    with open(name, 'wb') as f:\n","        pickle.dump(model, f)"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2022-09-10T04:34:46.504705Z","iopub.status.busy":"2022-09-10T04:34:46.504348Z","iopub.status.idle":"2022-09-10T04:34:47.584988Z","shell.execute_reply":"2022-09-10T04:34:47.583973Z","shell.execute_reply.started":"2022-09-10T04:34:46.504675Z"},"trusted":true},"outputs":[],"source":["save('pca.pkl', pca)\n","save('pca2.pkl', pca2)"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2022-09-10T04:34:47.587181Z","iopub.status.busy":"2022-09-10T04:34:47.586706Z","iopub.status.idle":"2022-09-10T04:34:48.072424Z","shell.execute_reply":"2022-09-10T04:34:48.071316Z","shell.execute_reply.started":"2022-09-10T04:34:47.587138Z"},"trusted":true},"outputs":[],"source":["from catboost import CatBoostRegressor\n","params = {'learning_rate': 0.2, \n","          'depth': 7, \n","          'l2_leaf_reg': 4, \n","          'loss_function': 'MultiRMSE', \n","          'eval_metric': 'MultiRMSE', \n","          'task_type': 'CPU', \n","          'iterations': 200,\n","          'od_type': 'Iter', \n","          'boosting_type': 'Plain', \n","          'bootstrap_type': 'Bayesian', \n","          'allow_const_label': True, \n","          'random_state': 1\n","         }\n","model = CatBoostRegressor(**params)"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2022-09-10T04:34:48.075038Z","iopub.status.busy":"2022-09-10T04:34:48.074362Z","iopub.status.idle":"2022-09-10T04:34:48.079871Z","shell.execute_reply":"2022-09-10T04:34:48.078432Z","shell.execute_reply.started":"2022-09-10T04:34:48.074999Z"},"trusted":true},"outputs":[],"source":["n = 1"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-09-10T04:34:48.081852Z","iopub.status.busy":"2022-09-10T04:34:48.081445Z"},"trusted":true},"outputs":[],"source":["np.random.seed(42)\n","all_row_indices = np.arange(train_inputs.shape[0])\n","np.random.shuffle(all_row_indices)\n","\n","kf = KFold(n_splits=5, shuffle=True, random_state=42)\n","\n","index = 0\n","score = []\n","\n","# model = Ridge(copy_X=False)\n","d = train_inputs.shape[0]//n\n","for i in range(0, n*d, d):\n","    print(f'start [{i}:{i+d}]')\n","    ind = all_row_indices[i:i+d]    \n","    for idx_tr, idx_va in kf.split(ind):\n","        X = train_inputs[ind]\n","        Y = train_target[ind] #.todense()\n","        Yva = train_targets[ind][idx_va]\n","        Xtr, Xva = X[idx_tr], X[idx_va]\n","        Ytr = Y[idx_tr]\n","        del X, Y\n","        gc.collect()\n","        print('Train...')\n","        model.fit(Xtr, Ytr)\n","        del Xtr, Ytr\n","        gc.collect()\n","        s = correlation_score(Yva.todense(), model.predict(Xva)@pca2.components_)\n","        score.append(s)\n","        print(index, s)\n","        del Xva, Yva\n","        gc.collect()\n","        pkl_filename = f\"model{index:02d}.pkl\"\n","        index += 1\n","        with open(pkl_filename, 'wb') as file:\n","            pickle.dump(model, file)\n","        break\n","    break\n","    gc.collect()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["del train_target, train_inputs, train_targets\n","gc.collect()"]},{"cell_type":"markdown","metadata":{},"source":["# Predicting"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["%%time\n","multi_test_x = scipy.sparse.load_npz(\"../input/multimodal-single-cell-as-sparse-matrix/test_multi_inputs_values.sparse.npz\")\n","multi_test_x = pca.transform(multi_test_x)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# test_sd = np.std(multi_test_x, axis=1).reshape(-1, 1)\n","# test_sd[test_sd == 0] = 1\n","# test_norm = (multi_test_x - np.mean(multi_test_x, axis=1).reshape(-1, 1)) / test_sd\n","# test_norm = test_norm.astype(np.float16)\n","# del multi_test_x\n","# gc.collect()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["test_len = multi_test_x.shape[0]\n","d = test_len//n\n","x = []\n","for i in range(n):\n","    x.append(multi_test_x[i*d:i*d+d])\n","del multi_test_x\n","gc.collect()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["index"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["preds = np.zeros((test_len, 23418), dtype='float16')\n","for i,xx in enumerate(x):\n","    for ind in range(index):\n","        print(ind, end=' ')\n","        with open(f'model{ind:02}.pkl', 'rb') as file:\n","            model = pickle.load(file)\n","        preds[i*d:i*d+d,:] += (model.predict(xx)@pca2.components_)/index\n","        gc.collect()\n","    print('')\n","    del xx\n","gc.collect()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["del x\n","gc.collect()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["np.save('preds.npy', preds)"]},{"cell_type":"markdown","metadata":{},"source":["# Creating submission\n","\n","We load the cells that will have to appear in submission."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["%%time\n","# Read the table of rows and columns required for submission\n","eval_ids = pd.read_parquet(\"../input/multimodal-single-cell-as-sparse-matrix/evaluation.parquet\")\n","# Convert the string columns to more efficient categorical types\n","#eval_ids.cell_id = eval_ids.cell_id.apply(lambda s: int(s, base=16))\n","eval_ids.cell_id = eval_ids.cell_id.astype(pd.CategoricalDtype())\n","eval_ids.gene_id = eval_ids.gene_id.astype(pd.CategoricalDtype())"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Prepare an empty series which will be filled with predictions\n","submission = pd.Series(name='target',\n","                       index=pd.MultiIndex.from_frame(eval_ids), \n","                       dtype=np.float32)\n","submission"]},{"cell_type":"markdown","metadata":{},"source":["We load the `index`  and `columns` of the original dataframe, as we need them to make the submission."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["%%time\n","y_columns = np.load(\"../input/multimodal-single-cell-as-sparse-matrix/train_multi_targets_idxcol.npz\",\n","                   allow_pickle=True)[\"columns\"]\n","\n","test_index = np.load(\"../input/multimodal-single-cell-as-sparse-matrix/test_multi_inputs_idxcol.npz\",\n","                    allow_pickle=True)[\"index\"]"]},{"cell_type":"markdown","metadata":{},"source":["We assign the predicted values to the correct row in the submission file."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["cell_dict = dict((k,v) for v,k in enumerate(test_index)) \n","assert len(cell_dict)  == len(test_index)\n","\n","gene_dict = dict((k,v) for v,k in enumerate(y_columns))\n","assert len(gene_dict) == len(y_columns)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["eval_ids_cell_num = eval_ids.cell_id.apply(lambda x:cell_dict.get(x, -1))\n","eval_ids_gene_num = eval_ids.gene_id.apply(lambda x:gene_dict.get(x, -1))\n","\n","valid_multi_rows = (eval_ids_gene_num !=-1) & (eval_ids_cell_num!=-1)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["submission.iloc[valid_multi_rows] = preds[eval_ids_cell_num[valid_multi_rows].to_numpy(),\n","eval_ids_gene_num[valid_multi_rows].to_numpy()]"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["del eval_ids_cell_num, eval_ids_gene_num, valid_multi_rows, eval_ids, test_index, y_columns\n","gc.collect()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["submission"]},{"cell_type":"markdown","metadata":{},"source":["# Merging with CITEseq predictions\n","\n","We use the CITEseq predictions from [this notebook](https://www.kaggle.com/code/vuonglam/lgbm-baseline-optuna-drop-constant-cite-task) by VuongLam."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["submission.reset_index(drop=True, inplace=True)\n","submission.index.name = 'row_id'"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["cite_submission = pd.read_csv(\"../input/msci-citeseq-keras-quickstart/submission.csv\")\n","cite_submission = cite_submission.set_index(\"row_id\")\n","cite_submission = cite_submission[\"target\"]"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["submission[submission.isnull()] = cite_submission[submission.isnull()]"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["submission"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["submission"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["submission.isnull().any()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["submission.to_csv(\"submission.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!head submission.csv"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!head submission.csv"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3.8.10 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"vscode":{"interpreter":{"hash":"31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"}}},"nbformat":4,"nbformat_minor":4}
